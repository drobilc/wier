\documentclass[conference]{IEEEtran}

\usepackage{tikz}
\usepackage{cite}

\usepackage[slovene]{babel}

% correct bad hyphenation here
\hyphenation{}

\begin{document}
	
	\title{Ekstrakcija podatkov}
	
	\author{Skupina \textbf{DOMACI-NJOKI}: Niki Bizjak, Bojan Vrangeloski, Uroš Škrjanc}
	
	\maketitle
	
	\begin{abstract}
		Cilj prve seminarske naloge je bil napisati pajka, ki zna s spleta prenašati spletne vsebine in jih shranjevati v podatkovno bazo. Pred iskanjem podatkov po taki podatkovni bazi, pa je treba prenesene vsebine najprej prečistiti in iz njih izluščiti pomembne informacije. V drugem seminarju si bomo ogledali tri različne načine za ekstrakcijo podatkov iz HTML vsebin.
	\end{abstract}
	
	\IEEEpeerreviewmaketitle
	
	\section{Uvod}
	
	Druga seminarska naloga pri predmetu Iskanje in ekstrakcija podatkov s spleta je namenjena pridobivanju informacij iz vsebin, ki jih je s spleta prenesel pajek. V seminarju smo si ogledali tri različne načine ekstrakcije - dva taka, ki zahtevata veliko uporabnikovega poseganja in razumevanja strukture strani in tretjega, ki zna informacije prepoznati in izluščiti avtomatično, s primerjavo podobnih spletnih strani.
	
	\section{Regularni izrazi}
	
	Regularni izrazi nam omogočajo učinkovito iskanje informacij v nizih z uporabo končnih avtomatov. Regularni izrazi lahko se uporabijo za preverjanje ce posamezen niz vsebuje podani vzorec iskanja. Pomagali smo si z python knjiznico import re. 
	Za spletno domeno Overstock smo uporabili naslednje (glej spodaj) regularne izraze. Najprej smo definirali regularne izraze za vsak iskani podatek posebaj, nato pa smo jih z ustreznimi vmesnimi regularnimi izrazi povezali v skupen regularni izraz, ki poišče vse omenjene podatke hkrati, naredimo (angl. pattern search), pa iscemo primerjavo.
	
	title_regex = "<b>(.+-[kK]t[^<]+)</b>"
	list_price_regex = "<b>List Price:</b></td><td align=\"left\"
	nowrap=\"nowrap\"><s>([^<]+)</s>"
	price_regex = "<span class=\"bigred\"><b>([^<]+)</b></span>"
	saving_regex = "<span class=\"littleorange\">([$][^<]+)</span>"
	content_regex = "<span class=\"normal\">([^<]+)"


	regex = title_regex + "</a><br>[\s]+<table><tbody><tr><td 
	valign=\"top\"><table>[\s]+<tbody><tr><td align=\"right\" nowrap=\"nowrap\">" + \
	list_price_regex + "</td></tr>[\s]+<tr><td align=\"right\"
	nowrap=\"nowrap\"><b>Price:</b></td><td align=\"left\" nowrap=\"nowrap\">" + \
	price_regex + "</td></tr>[\s]+<tr><td align=\"right\" nowrap=\"nowrap\"><b>You 
	Save:</b></td><td align=\"left\" nowrap=\"nowrap\">" + \
	saving_regex + "</td></tr>[\s]+</tbody></table>[\s]+</td><td valign=\"top\">" + \
	content_regeX

	Za spletno domeno RTV SLO smo uporabili naslednje (glej spodaj) regularne izraze, ki smo jih z ustreznimi vmesnimi izrazi povezali v skupen regularni izraz, ki poišče vse omenjene podatke hkrati

	title_regex = r"<h1>([^<]+)</h1>[\s]+<div class=\"subtitle\">([^<]+)</div>[\s]+<div class=\"article-meta-mobile\">[\s]+"
	author_regex = r"<div class=\"author-timestamp\">[\s]+<strong>([^<]+)</strong>([^<]+)</div>"
	lead_regex = r"<p class=\"lead\">([^<]+)</p>"
	content_regex = r"<\/div>[\s]*?<\/figure>[\s]*?<p([\s\S]*?)<div class=\"gallery\">"
	regex = title_regex + author_regex + r"[\s\S]*" + lead_regex + r"[\s\S]*" + content_regex

			
			
	Za spletno domeno Avtonet smo uporabili naslednje (glej spodaj) regularne izraze, katerih rezultate smo dodajali iterativno v posamezen iskani element oziroma Data Record.
			
	link_regex = "<a class=\"stretched-link\" href=\"([^\"]+)\"></a>"
	title_regex = "<div class=\"GO-Results-Naziv [^\"]+\">[\s]+<span>([^<]+)<\/span>[\s]+</div>"
	data_regex = "<tbody>[\s]*<tr>[\s]+<td class=\"w-25 d-none d-md-block pl-3\">[^<]+</td>[\s]+<td class=\"w-75 pl-3\">([^<]+)" \
				"</td>[\s]+</tr>(<tr>[\s]+<td class=\"d-none d-md-block pl-3\">[^<]+</td>[\s]+<td class=\"pl-3\">([^<]+)</td>[\s]+" \
				"</tr>)?<tr>[\s]+<td class=\"d-none d-md-block pl-3\">Gorivo</td>[\s]+<td class=\"pl-3\">([^<]+)</td>[\s]+</tr><tr>[\s]+" \
				"<td class=\"d-none d-md-block pl-3\">Menjalnik</td>[\s]+<td class=\"pl-3 text-truncate\">([^<]+)</td>[\s]+" \
				"</tr><tr class=\"d-none d-md-table-row\">[\s]+<td class=\"d-none d-md-block pl-3\">Motor</td>[\s]+<td class=\"pl-3 text-truncate\">[\s]+" \
				"([^<]+)</td>[\s]+</tr>[\s]+</tbody>[\s]+</table>"

	price_regex = "<div class=\"GO-Results-(Top-)?Price-TXT-[^BbSsTt\"]*\">([^<]+)</div>"

	



	\section{XPath}
	
	XPath je poizvedovalni jezik, ki je bil razvit za namene ekstrakcije podatkov iz XML podatkovnih struktur.
	
	\section{Avtomatična ekstrakcija podatkov}
	
	Na spletu se od uvedbe programskega jezika PHP naprej pojavlja dosti dinamičnih spletnih strani. Take strani hranijo podatke v podatkovni bazi in glede na dostopan URL naslov izvedejo poizvedbo v podatkovni bazi in na podlagi rezultata prikažejo podatke v uporabniku prijazni obliki. Pri avtomatični ekstrakciji podatkov, bi radi na podlagi dveh strani, ki imata enako strukturo, a drugačno vsebino, zgradili program, ki zna samodejno pridobiti podatke.
	
	V našem primeru smo za avtomatično ekstrakcijo podatkov uporabili algoritem \textsc{RoadRunner}~\cite{roadrunner, crescenzi2001automatic}. Ta sicer v originalni implementaciji deluje na seznamu žetonov (angl. token), v našem primeru pa smo za predstavitev HTML vsebin uporabili kar DOM drevo.
	
	\section{Zaključek}
	
	Pisanje regularnih in XPath izrazov za pridobivanje podatkov je zamudno in od razvijalca zahteva poznavanje oziroma razumevanje strukture spletne strani. Kljub temu, pa daje tak način ekstrakcije podatkov boljše rezultate, saj podatke označimo oziroma umestimo v nek kontekst. Razvijalec lahko npr. na mestih kjer se pojavijo cela števila, le-ta iz nizov pretvori v številčno predstavitev in s tem še dodatno opiše podatke. Avtomatična ekstrakcija podatkov je princip, pri katerem sistem na strani sam najde polja, ki vsebujejo podatke. Rezultati, tj. neoznačene izluščene informacije pa so v tem primeru pogosto pomanjkljivi oziroma težko razumljivi.
	
	Prva metoda je uporabna predvsem v primerih, ko je potrebno izluščiti podatke iz ene same spletne strani. Pisanje izrazov je časovno potratno in je smiselno, kadar vemo, da se bo struktura spletne strani spreminjala zelo redko.
	
	Druga metoda je zelo uporabna v primeru, ko imamo za ekstrahirati podatke iz ogromne količine različnih strani in smo za prihranek časa, pripravljeni žrtvovati natančnost.
	
	\bibliographystyle{IEEEtran}
	\bibliography{bibliography}
	
\end{document}
